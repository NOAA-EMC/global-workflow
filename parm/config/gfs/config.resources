#! /usr/bin/env bash

########## config.resources ##########
# Set resource information for job tasks
# e.g. walltime, node, cores per node, memory etc.
# Note: machine-specific resources should be placed into the appropriate config file:
#       config.resources.${machine}

if (( $# != 1 )); then

    echo "Must specify an input task argument to set resource variables!"
    echo "argument can be any one of the following:"
    echo "stage_ic aerosol_init"
    echo "prep prepsnowobs prepatmiodaobs"
    echo "atmanlinit atmanlvar atmanlfv3inc atmanlfinal"
    echo "atmensanlinit atmensanlletkf atmensanlfv3inc atmensanlfinal"
    echo "snowanl"
    echo "prepobsaero aeroanlinit aeroanlrun aeroanlfinal"
    echo "anal sfcanl analcalc analdiag fcst echgres"
    echo "upp atmos_products"
    echo "tracker genesis genesis_fsu"
    echo "verfozn verfrad vminmon fit2obs metp arch cleanup"
    echo "eobs ediag eomg eupd ecen esfc efcs epos earc"
    echo "init_chem mom6ic oceanice_products"
    echo "waveinit waveprep wavepostsbs wavepostbndpnt wavepostbndpntbll wavepostpnt"
    echo "wavegempak waveawipsbulls waveawipsgridded"
    echo "postsnd awips gempak npoess"
    echo "ocnanalprep prepoceanobs ocnanalbmat ocnanalrun ocnanalecen ocnanalletkf ocnanalchkpt ocnanalpost ocnanalvrfy"
    exit 1

fi

step=$1

echo "BEGIN: config.resources"

case ${machine} in
  "WCOSS2")
              npe_node_max=128
              # shellcheck disable=SC2034
              mem_node_max="500GB"
    ;;
  "HERA")
              npe_node_max=40
              # shellcheck disable=SC2034
              mem_node_max="96GB"
    ;;
  "GAEA")
              npe_node_max=128
              # shellcheck disable=SC2034
              mem_node_max="251GB"
    ;;
  "ORION")
              npe_node_max=40
              # shellcheck disable=SC2034
              mem_node_max="192GB"
    ;;
  "HERCULES")
              npe_node_max=80
              # shellcheck disable=SC2034
              mem_node_max="512GB"
    ;;
  "JET")
    case ${PARTITION_BATCH} in
      "xjet")
              npe_node_max=24
              # shellcheck disable=SC2034
              mem_node_max="61GB"
        ;;
      "vjet")
              npe_node_max=16
              # shellcheck disable=SC2034
              mem_node_max="61GB"
        ;;
      "sjet")
              npe_node_max=16
              # shellcheck disable=SC2034
              mem_node_max="29GB"
        ;;
      "kjet")
              npe_node_max=40
              # shellcheck disable=SC2034
              mem_node_max="88GB"
        ;;
      *)
        echo "FATAL ERROR: Unknown partition ${PARTITION_BATCH} specified for ${machine}"
        exit 3
    esac
    ;;
  "S4")
    case ${PARTITION_BATCH} in
      "s4")   npe_node_max=32
              # shellcheck disable=SC2034
              mem_node_max="168GB"
        ;;
      "ivy")
              npe_node_max=20
              # shellcheck disable=SC2034
              mem_node_max="128GB"
        ;;
      *)
        echo "FATAL ERROR: Unknown partition ${PARTITION_BATCH} specified for ${machine}"
        exit 3
    esac
    ;;
  "AWSPW")
    export PARTITION_BATCH="compute"
    npe_node_max=40
    # TODO Supply a max mem/node value for AWS
    # shellcheck disable=SC2034
    mem_node_max=""
    ;;
  "CONTAINER")
    npe_node_max=1
    # TODO Supply a max mem/node value for a container
    # shellcheck disable=SC2034
    mem_node_max=""
    ;;
  *)
    echo "FATAL ERROR: Unknown machine encountered by ${BASH_SOURCE[0]}"
    exit 2
    ;;
esac

export npe_node_max

case ${step} in
  "prep")
    export wtime='00:30:00'
    export npe=4
    export npe_node=2
    export nth=1
    export memory="40GB"
    ;;

  "prepsnowobs")
    export wtime="00:05:00"
    export npe=1
    export nth=1
    export npe_node=1
    ;;

  "prepatmiodaobs")
    export wtime="00:30:00"
    export npe=1
    export nth=1
    export npe_node=$(( npe_node_max / nth ))
    ;;

  "aerosol_init")
    export wtime="00:05:00"
    export npe=1
    export nth=1
    export npe_node=$(( npe_node_max / nth ))
    export NTASKS=${npe}
    export memory="6GB"
    ;;

  "waveinit")
    export wtime="00:10:00"
    export npe=12
    export nth=1
    export npe_node=$(( npe_node_max / nth ))
    export NTASKS=${npe}
    export memory="2GB"
    ;;

  "waveprep")
    export wtime="00:10:00"
    export npe_gdas=5
    export npe_gfs=65
    export nth_gdas=1
    export nth_gfs=1
    export npe_node_gdas=$(( npe_node_max / nth_gdas ))
    export npe_node_gfs=$(( npe_node_max / nth_gfs ))
    export NTASKS_gdas=${npe_gdas}
    export NTASKS_gfs=${npe_gfs}
    export memory_gdas="100GB"
    export memory_gfs="150GB"

    var_npe_node="npe_node_${RUN}"
    var_nth="nth_${RUN}"
    var_npe="npe_${RUN}"
    var_NTASKS="ntasks_${RUN}"
    # RUN is set to a single value at setup time, so these won't be found
    # TODO rework setup_xml.py to initialize RUN to the applicable option
    if [[ -n "${!var_npe_node+0}" ]]; then
      declare -x "npe_node"="${!var_npe_node}" \
                 "nth"="${!var_nth}" \
                 "npe"="${!var_npe}" \
                 "NTASKS"="${!var_NTASKS}"
    fi
    ;;

  "wavepostsbs")
    export wtime_gdas="00:20:00"
    export wtime_gfs="03:00:00"
    export npe=8
    export nth=1
    export npe_node=$(( npe_node_max / nth ))
    export NTASKS=${npe}
    export memory_gdas="10GB"
    export memory_gfs="10GB"
    ;;

  # The wavepost*pnt* jobs are I/O heavy and do not scale well to large nodes.
  # Limit the number of tasks/node to 40.
  "wavepostbndpnt")
    export wtime="03:00:00"
    export npe=240
    export nth=1
    export npe_node=$(( npe_node_max / nth ))
    export is_exclusive=True
    if [[ ${npe_node} -gt 40 ]]; then
        export npe_node=40
        export is_exclusive=False
    fi
    export NTASKS=${npe}
    ;;

  "wavepostbndpntbll")
    export wtime="01:00:00"
    export npe=448
    export nth=1
    export npe_node=$(( npe_node_max / nth ))
    export is_exclusive=True
    if [[ ${npe_node} -gt 40 ]]; then
        export npe_node=40
        export is_exclusive=False
    fi
    export NTASKS=${npe}
    ;;

  "wavepostpnt")
    export wtime="04:00:00"
    export npe=200
    export nth=1
    export npe_node=$(( npe_node_max / nth ))
    export is_exclusive=True
    if [[ ${npe_node} -gt 40 ]]; then
        export npe_node=40
        export is_exclusive=False
    fi
    export NTASKS=${npe}
    ;;

  "wavegempak")
    export wtime="02:00:00"
    export npe=1
    export nth=1
    export npe_node=$(( npe_node_max / nth ))
    export NTASKS=${npe}
    export memory="1GB"
    ;;

  "waveawipsbulls")
    export wtime="00:20:00"
    export npe=1
    export nth=1
    export npe_node=$(( npe_node_max / nth ))
    export NTASKS=${npe}
    export is_exclusive=True
    ;;

  "waveawipsgridded")
    export wtime="02:00:00"
    export npe=1
    export nth=1
    export npe_node=$(( npe_node_max / nth ))
    export NTASKS=${npe}
    export memory_gfs="1GB"
    ;;

  "atmanlinit")
    export layout_x=${layout_x_atmanl}
    export layout_y=${layout_y_atmanl}

    export layout_gsib_x=$(( layout_x * 3 ))
    export layout_gsib_y=$(( layout_y * 2 ))

    export wtime="00:10:00"
    export npe=1
    export nth=1
    export npe_node=$(( npe_node_max / nth ))
    export npe_node
    export memory="3072M"
    ;;

  "atmanlvar")
    export layout_x=${layout_x_atmanl}
    export layout_y=${layout_y_atmanl}

    export wtime="00:30:00"
    export npe_gdas=$(( layout_x * layout_y * 6 ))
    export npe_gfs=$(( layout_x * layout_y * 6 ))
    export nth_gdas=1
    export nth_gfs=${nth_gdas}
    export npe_node_gdas=$(( npe_node_max / nth_gdas ))
    export npe_node_gfs=$(( npe_node_max / nth_gfs ))
    export memory="96GB"
    export is_exclusive=True

    var_npe_node="npe_node_${RUN}"
    var_nth="nth_${RUN}"
    var_npe="npe_${RUN}"
    if [[ -n "${!var_npe_node+0}" ]]; then
      declare -x "npe_node"="${!var_npe_node}" \
                 "nth"="${!var_nth}" \
                 "npe"="${!var_npe}"
    fi
    ;;

  "atmanlfv3inc")
    export layout_x=${layout_x_atmanl}
    export layout_y=${layout_y_atmanl}

    export wtime="00:30:00"
    export npe_gdas=$(( layout_x * layout_y * 6 ))
    export npe_gfs=$(( layout_x * layout_y * 6 ))
    export nth_gdas=1
    export nth_gfs=${nth_gdas}
    export npe_node_gdas=$(( npe_node_max / nth_gdas ))
    export npe_node_gfs=$(( npe_node_max / nth_gfs ))
    export memory="96GB"
    export is_exclusive=True

    var_npe_node="npe_node_${RUN}"
    var_nth="nth_${RUN}"
    var_npe="npe_${RUN}"
    if [[ -n "${!var_npe_node+0}" ]]; then
      declare -x "npe_node"="${!var_npe_node}" \
                 "nth"="${!var_nth}" \
                 "npe"="${!var_npe}"
    fi
    ;;

  "atmanlfinal")
    export wtime="00:30:00"
    export npe=${npe_node_max}
    export nth=1
    export npe_node=$(( npe_node_max / nth ))
    export is_exclusive=True
    ;;

  "snowanl")
    # below lines are for creating JEDI YAML
    case ${CASE} in
      "C768")
        layout_x=6
        layout_y=6
        ;;
      "C384")
        layout_x=5
        layout_y=5
        ;;
      "C192" | "C96" | "C48")
        layout_x=1
        layout_y=1
        ;;
      *)
        echo "FATAL ERROR: Resources not defined for job ${step} at resolution ${CASE}"
        exit 4
    esac

    export layout_x
    export layout_y

    export wtime="00:15:00"
    export npe=$(( layout_x * layout_y * 6 ))
    export nth=1
    export npe_node=$(( npe_node_max / nth ))
    ;;

  "prepobsaero")
    export wtime="00:30:00"
    export npe=1
    export nth=1
    export npe_node=1
    export memory="96GB"
    ;;

  "aeroanlinit")
    # below lines are for creating JEDI YAML
    case ${CASE} in
      "C768")
        layout_x=8
        layout_y=8
        ;;
      "C384")
        layout_x=8
        layout_y=8
        ;;
      "C192" | "C96")
        layout_x=8
        layout_y=8
        ;;
      "C48" )
        # this case is for testing only
        layout_x=1
        layout_y=1
        ;;
      *)
        echo "FATAL ERROR: Resources not defined for job ${step} at resolution ${CASE}"
        exit 4
    esac

    export layout_x
    export layout_y
    export wtime="00:10:00"
    export npe=1
    export nth=1
    export npe_node=$(( npe_node_max / nth ))
    export memory="3072M"
    ;;

  "aeroanlrun")
    case ${CASE} in
      "C768")
        layout_x=8
        layout_y=8
        ;;
      "C384")
        layout_x=8
        layout_y=8
        ;;
      "C192" | "C96")
        layout_x=8
        layout_y=8
        ;;
      "C48" )
        # this case is for testing only
        layout_x=1
        layout_y=1
        ;;
      *)
        echo "FATAL ERROR: Resources not defined for job ${step} at resolution ${CASE}"
        exit 4
    esac

    export layout_x
    export layout_y

    export wtime="00:30:00"
    export npe_gdas=$(( layout_x * layout_y * 6 ))
    export npe_gfs=$(( layout_x * layout_y * 6 ))
    export nth_gdas=1
    export nth_gfs=1
    export npe_node_gdas=$(( npe_node_max / nth_gdas ))
    export npe_node_gfs=$(( npe_node_max / nth_gfs ))
    export is_exclusive=True

    var_npe_node="npe_node_${RUN}"
    var_nth="nth_${RUN}"
    var_npe="npe_${RUN}"
    if [[ -n "${!var_npe_node+0}" ]]; then
      declare -x "npe_node"="${!var_npe_node}" \
                 "nth"="${!var_nth}" \
                 "npe"="${!var_npe}"
    fi
    ;;

  "aeroanlfinal")
    export wtime="00:10:00"
    export npe=1
    export nth=1
    export npe_node=$(( npe_node_max / nth ))
    export memory="3072M"
    ;;

  "ocnanalprep")
    export wtime="00:10:00"
    export npe=1
    export nth=1
    export npe_node=$(( npe_node_max / nth ))
    export memory="24GB"
    ;;

  "prepoceanobs")
    export wtime="00:10:00"
    export npe=1
    export nth=1
    export npe_node=$(( npe_node_max / nth ))
    export memory="48GB"
    ;;

  "ocnanalbmat")
    npes=16
    case ${OCNRES} in
      "025") npes=480;;
      "050")  npes=16;;
      "500")  npes=16;;
      *)
        echo "FATAL ERROR: Resources not defined for job ${step} at resolution ${OCNRES}"
        exit 4
    esac

    export wtime="00:30:00"
    export npe=${npes}
    export nth=1
    export is_exclusive=True
    export npe_node=$(( npe_node_max / nth ))
    ;;

  "ocnanalrun")
    npes=16
    case ${OCNRES} in
      "025")
        npes=480
        memory="96GB"
        ;;
      "050")
        npes=16
        memory="96GB"
        ;;
      "500")
        npes=16
        memory="24GB"
        ;;
      *)
        echo "FATAL ERROR: Resources not defined for job ${step} at resolution ${OCNRES}"
        exit 4
    esac

    export wtime="00:15:00"
    export npe=${npes}
    export nth=1
    export is_exclusive=True
    export npe_node=$(( npe_node_max / nth ))
    export memory
    ;;

  "ocnanalecen")
    npes=16
    case ${OCNRES} in
      "025")
        npes=40
        memory="96GB"
        ;;
      "050")
        npes=16
        memory="96GB"
        ;;
      "500")
        npes=16
        memory="24GB"
        ;;
      *)
        echo "FATAL ERROR: Resources not defined for job ${step} at resolution ${OCNRES}"
        exit 4
    esac

    export wtime="00:10:00"
    export npe=${npes}
    export nth=1
    export is_exclusive=True
    export npe_node=$(( npe_node_max / nth ))
    export memory
    ;;

  "ocnanalletkf")
    npes=16
    case ${OCNRES} in
      "025")
        npes=480
        memory="96GB"
        ;;
      "050")
        npes=16
        memory="96GB"
        ;;
      "500")
        npes=16
        memory="24GB"
        ;;
      *)
        echo "FATAL ERROR: Resources not defined for job ${step} at resolution ${OCNRES}"
        exit 4
    esac

    export wtime="00:10:00"
    export npe=${npes}
    export nth=1
    export is_exclusive=True
    export npe_node=$(( npe_node_max / nth ))
    export memory
    ;;


  "ocnanalchkpt")
    export wtime="00:10:00"
    export npe=1
    export nth=1
    export npe_node=$(( npe_node_max / nth ))
    case ${OCNRES} in
      "025")
        memory="128GB"
        npes=40;;
      "050")
        memory="32GB"
        npes=16;;
      "500")
        memory="32GB"
        npes=8;;
      *)
        echo "FATAL ERROR: Resources not defined for job ${step} at resolution ${OCNRES}"
        exit 4
    esac
    export npe=${npes}
    export memory
    ;;

  "ocnanalpost")
    export wtime="00:30:00"
    export npe=${npe_node_max}
    export nth=1
    export npe_node=$(( npe_node_max / nth ))
    ;;

  "ocnanalvrfy")
    export wtime="00:35:00"
    export npe=1
    export nth=1
    export npe_node=$(( npe_node_max / nth ))
    export memory="24GB"
    ;;

  "anal")
    export wtime_gdas="01:20:00"
    export wtime_gfs="01:00:00"
    case ${CASE} in
      "C768")
        export npe_gdas=780
        export npe_gfs=825
        export nth=5
        ;;
      "C384")
        export npe_gdas=160
        export npe_gfs=160
        export nth=10
        ;;
      "C192" | "C96" | "C48")
        export npe_gdas=84
        export npe_gfs=84
        export nth=5
        ;;
      *)
        echo "FATAL ERROR: Resources not defined for job ${step} at resolution ${CASE}"
        exit 4
        ;;
    esac
    export npe_node=$(( npe_node_max / nth ))
    export nth=${nth}
    export npe_node=$(( npe_node_max / nth_cycle ))
    export is_exclusive=True

    var_npe="npe_${RUN}"
    if [[ -n "${!var_npe+0}" ]]; then
      declare -x "npe"="${!var_npe}"
    fi
    ;;

  "analcalc")
    export wtime="00:15:00"
    export npe=127
    export ntasks="${npe}"
    export nth=1
    export npe_node=$(( npe_node_max / nth ))
    export nth_echgres_gdas=4
    export nth_echgres_gfs=12
    export is_exclusive=True
    export memory="48GB"
    if [[ "${CASE}" == "C384" || "${CASE}" == "C768" ]]; then
       export memory="${mem_node_max}"
    fi

    var_nth="nth_echgres_${RUN}"
    if [[ -n "${!var_nth+0}" ]]; then
      declare -x "nth"="${!var_nth}"
    fi
    ;;

  "analdiag")
    export wtime="00:15:00"
    export npe=96             # Should be at least twice npe
    export nth=1
    export npe_node=$(( npe_node_max / nth ))
    export memory="48GB"
    ;;

  "sfcanl")
    export wtime="00:20:00"
    export npe=6
    export nth=1
    export npe_node=$(( npe_node_max / nth ))
    export is_exclusive=True
    ;;

  "fcst" | "efcs")
    export is_exclusive=True

    if [[ "${step}" == "fcst" ]]; then
      _CDUMP_LIST=${CDUMP:-"gdas gfs"}
    elif [[ "${step}" == "efcs" ]]; then
      _CDUMP_LIST=${CDUMP:-"enkfgdas enkfgfs"}
    fi

    # During workflow creation, we need resources for all CDUMPs and CDUMP is undefined
    for _CDUMP in ${_CDUMP_LIST}; do
      if [[ "${_CDUMP}" =~ "gfs" ]]; then
        export layout_x=${layout_x_gfs}
        export layout_y=${layout_y_gfs}
        export WRITE_GROUP=${WRITE_GROUP_GFS}
        export WRTTASK_PER_GROUP_PER_THREAD=${WRTTASK_PER_GROUP_PER_THREAD_GFS}
        ntasks_fv3=${ntasks_fv3_gfs}
        ntasks_quilt=${ntasks_quilt_gfs}
        nthreads_fv3=${nthreads_fv3_gfs}
        nthreads_ufs=${nthreads_ufs_gfs}
        # Will not be set if we are skipping the mediator
        nthreads_mediator=${nthreads_mediator_gfs:-}
      elif [[ "${_CDUMP}" =~ "gdas" ]]; then
        export layout_x=${layout_x_gdas}
        export layout_y=${layout_y_gdas}
        export WRITE_GROUP=${WRITE_GROUP_GDAS}
        export WRTTASK_PER_GROUP_PER_THREAD=${WRTTASK_PER_GROUP_PER_THREAD_GDAS}
        ntasks_fv3=${ntasks_fv3_gdas}
        ntasks_quilt=${ntasks_quilt_gdas}
        nthreads_fv3=${nthreads_fv3_gdas}
        nthreads_ufs=${nthreads_ufs_gdas}
        nthreads_mediator=${nthreads_mediator_gdas:-}
      fi

      # Determine if using ESMF-managed threading or traditional threading
      # If using traditional threading, set them to 1
      if [[ "${USE_ESMF_THREADING:-}" == "YES" ]]; then
        export UFS_THREADS=1
      else  # traditional threading
        export UFS_THREADS=${nthreads_ufs:-1}
        nthreads_fv3=1
        nthreads_mediator=1
        [[ "${DO_WAVE}" == "YES" ]] && nthreads_ww3=1
        [[ "${DO_OCN}" == "YES" ]] && nthreads_mom6=1
        [[ "${DO_ICE}" == "YES" ]] && nthreads_cice6=1
      fi

      if (( ntiles > 6 )); then
        export layout_x_nest=${layout_x_nest:-10}
        export layout_y_nest=${layout_y_nest:-10}
        export npx_nest=${npx_nest:-1441}
        export npy_nest=${npy_nest:-961}
      fi

      # PETS for the atmosphere dycore
      (( FV3PETS = ntasks_fv3 * nthreads_fv3 ))
      echo "FV3 using (nthreads, PETS) = (${nthreads_fv3}, ${FV3PETS})"

      # PETS for quilting
      if [[ "${QUILTING:-}" == ".true." ]]; then
        (( QUILTPETS = ntasks_quilt * nthreads_fv3 ))
        (( WRTTASK_PER_GROUP = WRTTASK_PER_GROUP_PER_THREAD ))
        export WRTTASK_PER_GROUP
      else
        QUILTPETS=0
      fi
      echo "QUILT using (nthreads, PETS) = (${nthreads_fv3}, ${QUILTPETS})"

      # Total PETS for the atmosphere component
      ATMTHREADS=${nthreads_fv3}
      (( ATMPETS = FV3PETS + QUILTPETS ))
      export ATMPETS ATMTHREADS
      echo "FV3ATM using (nthreads, PETS) = (${ATMTHREADS}, ${ATMPETS})"

      # Total PETS for the coupled model (starting w/ the atmosphere)
      NTASKS_TOT=${ATMPETS}

      # The mediator PETS can overlap with other components, usually it lands on the atmosphere tasks.
      # However, it is suggested limiting mediator PETS to 300, as it may cause the slow performance.
      # See https://docs.google.com/document/d/1bKpi-52t5jIfv2tuNHmQkYUe3hkKsiG_DG_s6Mnukog/edit
      # TODO: Update reference when moved to ufs-weather-model RTD
      MEDTHREADS=${nthreads_mediator:-1}
      MEDPETS=${MEDPETS:-${FV3PETS}}
      (( "${MEDPETS}" > 300 )) && MEDPETS=300
      export MEDPETS MEDTHREADS
      echo "MEDIATOR using (threads, PETS) = (${MEDTHREADS}, ${MEDPETS})"

      CHMPETS=0; CHMTHREADS=0
      if [[ "${DO_AERO}" == "YES" ]]; then
        # GOCART shares the same grid and forecast tasks as FV3 (do not add write grid component tasks).
        (( CHMTHREADS = ATMTHREADS ))
        (( CHMPETS = FV3PETS ))
        # Do not add to NTASKS_TOT
        echo "GOCART using (threads, PETS) = (${CHMTHREADS}, ${CHMPETS})"
      fi
      export CHMPETS CHMTHREADS

      WAVPETS=0; WAVTHREADS=0
      if [[ "${DO_WAVE}" == "YES" ]]; then
        (( WAVPETS = ntasks_ww3 * nthreads_ww3 ))
        (( WAVTHREADS = nthreads_ww3 ))
        echo "WW3 using (threads, PETS) = (${WAVTHREADS}, ${WAVPETS})"
        (( NTASKS_TOT = NTASKS_TOT + WAVPETS ))
      fi
      export WAVPETS WAVTHREADS

      OCNPETS=0; OCNTHREADS=0
      if [[ "${DO_OCN}" == "YES" ]]; then
        (( OCNPETS = ntasks_mom6 * nthreads_mom6 ))
        (( OCNTHREADS = nthreads_mom6 ))
        echo "MOM6 using (threads, PETS) = (${OCNTHREADS}, ${OCNPETS})"
        (( NTASKS_TOT = NTASKS_TOT + OCNPETS ))
      fi
      export OCNPETS OCNTHREADS

      ICEPETS=0; ICETHREADS=0
      if [[ "${DO_ICE}" == "YES" ]]; then
        (( ICEPETS = ntasks_cice6 * nthreads_cice6 ))
        (( ICETHREADS = nthreads_cice6 ))
        echo "CICE6 using (threads, PETS) = (${ICETHREADS}, ${ICEPETS})"
        (( NTASKS_TOT = NTASKS_TOT + ICEPETS ))
      fi
      export ICEPETS ICETHREADS

      echo "Total PETS for ${_CDUMP} = ${NTASKS_TOT}"

      declare -x "npe_${_CDUMP}"="${NTASKS_TOT}"
      declare -x "nth_${_CDUMP}"="${UFS_THREADS}"
      declare -x "npe_node_${_CDUMP}"="${npe_node_max}"

    done

    case "${CASE}" in
      "C48" | "C96" | "C192")
        declare -x "wtime_gdas"="00:20:00"
        declare -x "wtime_enkfgdas"="00:20:00"
        declare -x "wtime_gfs"="03:00:00"
        declare -x "wtime_enkfgfs"="00:20:00"
        ;;
      "C384")
        declare -x "wtime_gdas"="00:30:00"
        declare -x "wtime_enkfgdas"="00:30:00"
        declare -x "wtime_gfs"="06:00:00"
        declare -x "wtime_enkfgfs"="00:30:00"
        ;;
      "C768" | "C1152")
        # Not valid resolutions for ensembles
        declare -x "wtime_gdas"="00:40:00"
        declare -x "wtime_gfs"="06:00:00"
        ;;
      *)
        echo "FATAL ERROR: Resources not defined for job ${step} at resolution ${CASE}"
        exit 4
        ;;
    esac

    var_npe_node="npe_node_${RUN}"
    var_nth="nth_${RUN}"
    var_npe="npe_${RUN}"
    if [[ -n "${!var_npe_node+0}" ]]; then
      declare -x "npe_node"="${!var_npe_node}" \
                 "nth"="${!var_nth}" \
                 "npe"="${!var_npe}"
    fi

    unset _CDUMP _CDUMP_LIST
    unset NTASKS_TOT
    ;;

  "oceanice_products")
    export wtime="00:15:00"
    export npe=1
    export npe_node=1
    export nth=1
    export memory="96GB"
    ;;

  "upp")
    case "${CASE}" in
      "C48" | "C96")
        export npe=${CASE:1}
      ;;
      "C192" | "C384" | "C768" )
        export npe=120
        export memory="${mem_node_max}"
      ;;
      *)
        echo "FATAL ERROR: Resources not defined for job ${step} at resolution ${CASE}"
        exit 4
      ;;
    esac
    export npe_node=${npe}

    export nth=1

    export wtime="00:15:00"
    if (( npe_node > npe_node_max )); then
      export npe_node=${npe_node_max}
    fi
    export is_exclusive=True
    ;;

  "atmos_products")
    export wtime="00:15:00"
    export npe=24
    export nth=1
    export npe_node="${npe}"
    export is_exclusive=True
    ;;

  "verfozn")
    export wtime="00:05:00"
    export npe=1
    export nth=1
    export npe_node=1
    export memory="1G"
    ;;

  "verfrad")
    export wtime="00:40:00"
    export npe=1
    export nth=1
    export npe_node=1
    export memory="5G"
    ;;

  "vminmon")
    export wtime="00:05:00"
    export npe=1
    export nth=1
    export npe_node=1
    export memory="1G"
    ;;

  "tracker")
    export wtime="00:10:00"
    export npe=1
    export nth=1
    export npe_node=1
    export memory="4G"
    ;;

  "genesis")
    export wtime="00:25:00"
    export npe=1
    export nth=1
    export npe_node=1
    export memory="10G"
    ;;

  "genesis_fsu")
    export wtime="00:10:00"
    export npe=1
    export nth=1
    export npe_node=1
    export memory="10G"
    ;;

  "fit2obs")
    export wtime="00:20:00"
    export npe=3
    export nth=1
    export npe_node=1
    export memory="20G"
    ;;

  "metp")
    export nth=1
    export wtime_gdas="03:00:00"
    export wtime_gfs="06:00:00"
    export npe=4
    export npe_node=4
    export is_exclusive=True
    ;;

  "echgres")
    export wtime="00:10:00"
    export npe=3
    export nth=${npe_node_max}
    export npe_node=1
    ;;

  "init")
    export wtime="00:30:00"
    export npe=24
    export nth=1
    export npe_node=6
    export memory="70GB"
    ;;

  "init_chem")
    export wtime="00:30:00"
    export npe=1
    export npe_node=1
    export is_exclusive=True
    ;;

  "mom6ic")
    export wtime="00:30:00"
    export npe=24
    export npe_node=24
    export is_exclusive=True
    ;;

  "arch" | "earc" | "getic")
    declare -x "wtime"="06:00:00"
    declare -x "npe"="1"
    declare -x "npe_node"="1"
    declare -x "nth"="1"
    declare -x "memory"="4096M"
    ;;

  "cleanup")
    export wtime="00:15:00"
    export npe=1
    export npe_node=1
    export nth=1
    export memory="4096M"
    ;;

  "stage_ic")
    export wtime="00:15:00"
    export npe=1
    export npe_node=1
    export nth=1
    export is_exclusive=True
    ;;

  "atmensanlinit")
    export layout_x=${layout_x_atmensanl}
    export layout_y=${layout_y_atmensanl}

    export wtime="00:10:00"
    export npe=1
    export nth=1
    export npe_node=$(( npe_node_max / nth ))
    export memory="3072M"
    ;;

  "atmensanlletkf")
    export layout_x=${layout_x_atmensanl}
    export layout_y=${layout_y_atmensanl}

    export wtime="00:30:00"
    export npe_enkfgdas=$(( layout_x * layout_y * 6 ))
    export npe_enkfgfs=$(( layout_x * layout_y * 6 ))
    export nth_enkfgdas=1
    export nth_enkfgfs=${nth_enkfgdas}
    export npe_node_enkfgdas=$(( npe_node_max / nth_enkfgdas ))
    export npe_node_enkfgfs=$(( npe_node_max / nth_enkfgfs ))
    export memory="96GB"
    export is_exclusive=True

    var_npe_node="npe_node_${RUN}"
    var_nth="nth_${RUN}"
    var_npe="npe_${RUN}"
    # RUN is set to a single value at setup time, so these won't be found
    # TODO rework setup_xml.py to initialize RUN to the applicable option
    if [[ -n "${!var_npe_node+0}" ]]; then
      declare -x "npe_node"="${!var_npe_node}" \
                 "nth"="${!var_nth}" \
                 "npe"="${!var_npe}"
    fi
    ;;

  "atmensanlfv3inc")
    export layout_x=${layout_x_atmensanl}
    export layout_y=${layout_y_atmensanl}

    export wtime="00:30:00"
    export npe_enkfgdas=$(( layout_x * layout_y * 6 ))
    export npe_enkfgfs=$(( layout_x * layout_y * 6 ))
    export nth_enkfgdas=1
    export nth_enkfgfs=${nth_enkfgdas}
    export npe_node_enkfgdas=$(( npe_node_max / nth_enkfgdas ))
    export npe_node_enkfgfs=$(( npe_node_max / nth_enkfgfs ))
    export memory="96GB"
    export is_exclusive=True

    var_npe_node="npe_node_${RUN}"
    var_nth="nth_${RUN}"
    var_npe="npe_${RUN}"
    # RUN is set to a single value at setup time, so these won't be found
    # TODO rework setup_xml.py to initialize RUN to the applicable option
    if [[ -n "${!var_npe_node+0}" ]]; then
      declare -x "npe_node"="${!var_npe_node}" \
                 "nth"="${!var_nth}" \
                 "npe"="${!var_npe}"
    fi
    ;;

  "atmensanlfinal")
    export wtime="00:30:00"
    export npe=${npe_node_max}
    export nth=1
    export npe_node=$(( npe_node_max / nth ))
    export is_exclusive=True
    ;;

  "eobs" | "eomg")
    export wtime="00:15:00"
    export wtime="00:30:00"
    case ${CASE} in
      "C768")                 export npe=200;;
      "C384")                 export npe=100;;
      "C192" | "C96" | "C48") export npe=40;;
      *)
        echo "FATAL ERROR: Resources not defined for job ${step} at resolution ${CASE}"
        exit 4
        ;;
    esac
    export nth=2
    # NOTE The number of tasks and cores used must be the same for eobs
    # See https://github.com/NOAA-EMC/global-workflow/issues/2092 for details
    export npe_node=$(( npe_node_max / nth ))
    export is_exclusive=True
    # Unset npe_node if it is not a multiple of npe_node_max
    # to prevent dropping data on the floor.  This should be set int
    # config.resources.{machine} instead.  This will result in an error at
    # experiment setup time if not set in config.resources.{machine}.
    if [[ $(( npe_node_max % npe_node )) != 0 ]]; then
      unset npe_node_max
    fi
    ;;

  "ediag")
    export wtime="00:15:00"
    export npe=48
    export nth=1
    export npe_node=$(( npe_node_max / nth ))
    export memory="30GB"
    ;;

  "eupd")
    export wtime="00:30:00"
    case ${CASE} in
      "C768")
        export npe=480
        export nth=6
        ;;
      "C384")
        export npe=270
        export nth=8
        ;;
      "C192" | "C96" | "C48")
        export npe=42
        export nth=2
        ;;
      *)
        echo "FATAL ERROR: Resources not defined for job ${step} at resolution ${CASE}"
        exit 4
        ;;
    esac
    export npe_node=$(( npe_node_max / nth ))
    export is_exclusive=True
    ;;

  "ecen")
    export wtime="00:10:00"
    export npe=80
    export nth=4
    if [[ ${CASE} == "C384" || ${CASE} == "C192" || ${CASE} == "C96" || ${CASE} == "C48" ]]; then
      export nth=2
    fi
    export npe_node=$(( npe_node_max / nth ))
    export npe_node_cycle=${npe_node}
    export is_exclusive=True
    ;;

  "esfc")
    export wtime="00:15:00"
    export npe=80
    export nth=1
    export npe_node=$(( npe_node_max / nth ))
    export nth_cycle=${nth}
    export npe_node_cycle=$(( npe_node_max / nth_cycle ))
    ;;

  "epos")
    export wtime="00:15:00"
    [[ ${CASE} == "C768" ]] && export wtime="00:25:00"
    export npe=80
    export nth=1
    export npe_node=$(( npe_node_max / nth ))
    export is_exclusive=True
    ;;

  "postsnd")
    export wtime="02:00:00"
    export npe=40
    export nth=8
    export npe_node=10
    export npe=9
    export npe_node=1
    postsnd_req_cores=$(( npe_node * nth ))
    if (( postsnd_req_cores > npe_node_max )); then
        export npe_node=$(( npe_node_max / nth ))
    fi
    export is_exclusive=True
    ;;

  "awips")
    export wtime="03:30:00"
    export npe=1
    export npe_node=1
    export nth=1
    export memory="3GB"
    ;;

  "npoess")
    export wtime="03:30:00"
    export npe=1
    export npe_node=1
    export nth=1
    export memory="3GB"
    ;;

  "gempak")
    export wtime="03:00:00"
    export npe_gdas=2
    export npe_gfs=28
    export npe_node_gdas=2
    export npe_node_gfs=28
    export nth=1
    export memory_gdas="4GB"
    export memory_gfs="2GB"

    var_npe_node="npe_node_${RUN}"
    var_npe="npe_${RUN}"
    # RUN is set to a single value at setup time, so these won't be found
    # TODO rework setup_xml.py to initialize RUN to the applicable option
    if [[ -n "${!var_npe_node+0}" ]]; then
      declare -x "npe_node"="${!var_npe_node}" \
                 "npe"="${!var_npe}"
    fi
    ;;

  "mos_stn_prep")
    export wtime="00:10:00"
    export npe=3
    export npe_node=3
    export nth=1
    export memory="5GB"
    export NTASK="${npe}"
    export PTILE="${npe_node}"
    ;;

  "mos_grd_prep")
    export wtime="00:10:00"
    export npe=4
    export npe_node=4
    export nth=1
    export memory="16GB"
    export NTASK="${npe}"
    export PTILE="${npe_node}"
    ;;

  "mos_ext_stn_prep")
    export wtime="00:15:00"
    export npe=2
    export npe_node=2
    export nth=1
    export memory="5GB"
    export NTASK="${npe}"
    export PTILE="${npe_node}"
    ;;

  "mos_ext_grd_prep")
    export wtime="00:10:00"
    export npe=7
    export npe_node=7
    export nth=1
    export memory="3GB"
    export NTASK="${npe}"
    export PTILE="${npe_node}"
    ;;

  "mos_stn_fcst")
    export wtime="00:10:00"
    export npe=5
    export npe_node=5
    export nth=1
    export memory="40GB"
    export NTASK="${npe}"
    export PTILE="${npe_node}"
    ;;

  "mos_grd_fcst")
    export wtime="00:10:00"
    export npe=7
    export npe_node=7
    export nth=1
    export memory="50GB"
    export NTASK="${npe}"
    export PTILE="${npe_node}"
    ;;

  "mos_ext_stn_fcst")
    export wtime="00:20:00"
    export npe=3
    export npe_node=3
    export nth=1
    export memory="50GB"
    export NTASK="${npe}"
    export PTILE="${npe_node}"
    export prepost=True
    ;;

  "mos_ext_grd_fcst")
    export wtime="00:10:00"
    export npe=7
    export npe_node=7
    export nth=1
    export memory="50GB"
    export NTASK="${npe}"
    export PTILE="${npe_node}"
    ;;

  "mos_stn_prdgen")
    export wtime="00:10:00"
    export npe=1
    export npe_node=1
    export nth=1
    export memory="15GB"
    export NTASK="${npe}"
    export PTILE="${npe_node}"
    export prepost=True
    ;;

  "mos_grd_prdgen")
    export wtime="00:40:00"
    export npe=72
    export npe_node=18
    export nth=4
    export memory="20GB"
    export NTASK="${npe}"
    export PTILE="${npe_node}"
    export OMP_NUM_THREADS="${nth}"
    ;;

  "mos_ext_stn_prdgen")
    export wtime="00:10:00"
    export npe=1
    export npe_node=1
    export nth=1
    export memory="15GB"
    export NTASK="${npe}"
    export PTILE="${npe_node}"
    export prepost=True
    ;;

  "mos_ext_grd_prdgen")
    export wtime="00:30:00"
    export npe=96
    export npe_node=6
    export nth=16
    export memory="30GB"
    export NTASK="${npe}"
    export PTILE="${npe_node}"
    export OMP_NUM_THREADS="${nth}"
    ;;

  "mos_wx_prdgen")
    export wtime="00:10:00"
    export npe=4
    export npe_node=2
    export nth=2
    export memory="10GB"
    export NTASK="${npe}"
    export PTILE="${npe_node}"
    export OMP_NUM_THREADS="${nth}"
    ;;

  "mos_wx_ext_prdgen")
    export wtime="00:10:00"
    export npe=4
    export npe_node=2
    export nth=2
    export memory="10GB"
    export NTASK="${npe}"
    export PTILE="${npe_node}"
    export OMP_NUM_THREADS="${nth}"
    ;;

  *)
    echo "FATAL ERROR: Invalid job ${step} passed to ${BASH_SOURCE[0]}"
    exit 1
    ;;

esac

# Unset dynamic variable names
unset var_NTASKS \
      var_npe \
      var_npe_node \
      var_nth

# Get machine-specific resources, overriding/extending the above assignments
if [[ -f "${EXPDIR}/config.resources.${machine}" ]]; then
   source "${EXPDIR}/config.resources.${machine}"
fi

echo "END: config.resources"
