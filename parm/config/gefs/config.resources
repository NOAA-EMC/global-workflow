#! /usr/bin/env bash

########## config.resources ##########
# Set resource information for job tasks
# e.g. walltime, node, cores per node, memory etc.

if (( $# != 1 )); then

    echo "Must specify an input task argument to set resource variables!"
    exit 1

fi

step=$1

echo "BEGIN: config.resources"

case ${machine} in
  "WCOSS2")   npe_node_max=128;;
  "HERA")     npe_node_max=40;;
  "ORION")    npe_node_max=40;;
  "HERCULES") npe_node_max=80;;
  "JET")
    case ${PARTITION_BATCH} in
      "xjet")          npe_node_max=24;;
      "vjet" | "sjet") npe_node_max=16;;
      "kjet")          npe_node_max=40;;
      *)
        echo "FATAL ERROR: Unknown partition ${PARTITION_BATCH} specified for ${machine}"
        exit 3
    esac
    ;;
  "S4")
    case ${PARTITION_BATCH} in
      "s4")  npe_node_max=32;;
      "ivy") npe_node_max=20;;
      *)
        echo "FATAL ERROR: Unknown partition ${PARTITION_BATCH} specified for ${machine}"
        exit 3
    esac
    ;;
  "AWSPW")
    export PARTITION_BATCH="compute"
    npe_node_max=40
    ;;
  *)
    echo "FATAL ERROR: Unknown machine encountered by ${BASH_SOURCE[0]}"
    exit 2
    ;;
esac
export npe_node_max

case ${step} in

  "stage_ic")
    export wtime_stage_ic="00:15:00"
    export npe_stage_ic=1
    export npe_node_stage_ic=1
    export nth_stage_ic=1
    export is_exclusive=True
    ;;

  "waveinit")
    export wtime_waveinit="00:10:00"
    export npe_waveinit=12
    export nth_waveinit=1
    export npe_node_waveinit=$(( npe_node_max / nth_waveinit ))
    export NTASKS=${npe_waveinit}
    export memory_waveinit="2GB"
    ;;

  "prep_emissions")
    export wtime_prep_emissions="00:10:00"
    export npe_prep_emissions=1
    export nth_prep_emissions=1
    export npe_node_prep_emissions=$(( npe_node_max / nth_prep_emissions ))
    export memory_prep_emissions="1GB"
    ;;

  "fcst" | "efcs")
    export is_exclusive=True

    _RUN_LIST=${RUN:-"gefs gfs"}

    # During workflow creation, we need resources for all RUNs and RUN is undefined
    for _RUN in ${_RUN_LIST}; do
      if [[ "${_RUN}" =~ "gfs" ]]; then
        export layout_x=${layout_x_gfs}
        export layout_y=${layout_y_gfs}
        export WRITE_GROUP=${WRITE_GROUP_GFS}
        export WRTTASK_PER_GROUP_PER_THREAD=${WRTTASK_PER_GROUP_PER_THREAD_GFS}
        ntasks_fv3=${ntasks_fv3_gfs}
        ntasks_quilt=${ntasks_quilt_gfs}
        nthreads_fv3=${nthreads_fv3_gfs}
        nthreads_ufs=${nthreads_ufs_gfs}
      fi

      # Determine if using ESMF-managed threading or traditional threading
      # If using traditional threading, set them to 1
      if [[ "${USE_ESMF_THREADING:-}" == "YES" ]]; then
        export UFS_THREADS=1
      else  # traditional threading
        export UFS_THREADS=${nthreads_ufs:-1}
        nthreads_fv3=1
        nthreads_mediator=1
        [[ "${DO_WAVE}" == "YES" ]] && nthreads_ww3=1
        [[ "${DO_OCN}" == "YES" ]] && nthreads_mom6=1
        [[ "${DO_ICE}" == "YES" ]] && nthreads_cice6=1
      fi

      # PETS for the atmosphere dycore
      (( FV3PETS = ntasks_fv3 * nthreads_fv3 ))
      echo "FV3 using (nthreads, PETS) = (${nthreads_fv3}, ${FV3PETS})"

      # PETS for quilting
      if [[ "${QUILTING:-}" == ".true." ]]; then
        (( QUILTPETS = ntasks_quilt * nthreads_fv3 ))
        (( WRTTASK_PER_GROUP = WRTTASK_PER_GROUP_PER_THREAD ))
        export WRTTASK_PER_GROUP
      else
        QUILTPETS=0
      fi
      echo "QUILT using (nthreads, PETS) = (${nthreads_fv3}, ${QUILTPETS})"

      # Total PETS for the atmosphere component
      ATMTHREADS=${nthreads_fv3}
      (( ATMPETS = FV3PETS + QUILTPETS ))
      export ATMPETS ATMTHREADS
      echo "FV3ATM using (nthreads, PETS) = (${ATMTHREADS}, ${ATMPETS})"

      # Total PETS for the coupled model (starting w/ the atmosphere)
      NTASKS_TOT=${ATMPETS}

      # The mediator PETS can overlap with other components, usually it lands on the atmosphere tasks.
      # However, it is suggested limiting mediator PETS to 300, as it may cause the slow performance.
      # See https://docs.google.com/document/d/1bKpi-52t5jIfv2tuNHmQkYUe3hkKsiG_DG_s6Mnukog/edit
      # TODO: Update reference when moved to ufs-weather-model RTD
      MEDTHREADS=${nthreads_mediator:-1}
      MEDPETS=${MEDPETS:-${FV3PETS}}
      (( "${MEDPETS}" > 300 )) && MEDPETS=300
      export MEDPETS MEDTHREADS
      echo "MEDIATOR using (threads, PETS) = (${MEDTHREADS}, ${MEDPETS})"

      CHMPETS=0; CHMTHREADS=0
      if [[ "${DO_AERO}" == "YES" ]]; then
        # GOCART shares the same grid and forecast tasks as FV3 (do not add write grid component tasks).
        (( CHMTHREADS = ATMTHREADS ))
        (( CHMPETS = FV3PETS ))
        # Do not add to NTASKS_TOT
        echo "GOCART using (threads, PETS) = (${CHMTHREADS}, ${CHMPETS})"
      fi
      export CHMPETS CHMTHREADS

      WAVPETS=0; WAVTHREADS=0
      if [[ "${DO_WAVE}" == "YES" ]]; then
        (( WAVPETS = ntasks_ww3 * nthreads_ww3 ))
        (( WAVTHREADS = nthreads_ww3 ))
        echo "WW3 using (threads, PETS) = (${WAVTHREADS}, ${WAVPETS})"
        (( NTASKS_TOT = NTASKS_TOT + WAVPETS ))
      fi
      export WAVPETS WAVTHREADS

      OCNPETS=0; OCNTHREADS=0
      if [[ "${DO_OCN}" == "YES" ]]; then
        (( OCNPETS = ntasks_mom6 * nthreads_mom6 ))
        (( OCNTHREADS = nthreads_mom6 ))
        echo "MOM6 using (threads, PETS) = (${OCNTHREADS}, ${OCNPETS})"
        (( NTASKS_TOT = NTASKS_TOT + OCNPETS ))
      fi
      export OCNPETS OCNTHREADS

      ICEPETS=0; ICETHREADS=0
      if [[ "${DO_ICE}" == "YES" ]]; then
        (( ICEPETS = ntasks_cice6 * nthreads_cice6 ))
        (( ICETHREADS = nthreads_cice6 ))
        echo "CICE6 using (threads, PETS) = (${ICETHREADS}, ${ICEPETS})"
        (( NTASKS_TOT = NTASKS_TOT + ICEPETS ))
      fi
      export ICEPETS ICETHREADS

      echo "Total PETS for ${_RUN} = ${NTASKS_TOT}"

      declare -x "npe_${_RUN}"="${NTASKS_TOT}"
      declare -x "nth_${_RUN}"="${UFS_THREADS}"
      declare -x "npe_node_${_RUN}"="${npe_node_max}"

    done

    case "${CASE}" in
      "C48" | "C96" | "C192")
        declare -x "wtime_gefs"="03:00:00"
        declare -x "wtime_gfs"="03:00:00"
        ;;
      "C384" | "C768" | "C1152")
        declare -x "wtime_gefs"="06:00:00"
        declare -x "wtime_gfs"="06:00:00"
        ;;
      *)
        echo "FATAL ERROR: Resources not defined for job ${step} at resolution ${CASE}"
        exit 4
        ;;
    esac

    unset _RUN _RUN_LIST
    unset NTASKS_TOT
    ;;

  "atmos_products")
    export wtime="00:15:00"
    export npe=24
    export nth=1
    export npe_node="${npe}"
    export is_exclusive=True
    ;;

  "atmos_ensstat")
    export wtime="00:30:00"
    export npe=6
    export nth=1
    export npe_node="${npe}"
    export is_exclusive=True
    ;;

  "oceanice_products")
    export wtime="00:15:00"
    export npe=1
    export npe_node=1
    export nth=1
    export memory="96GB"
    ;;

  "wavepostsbs")
    export wtime="03:00:00"
    export npe=1
    export nth=1
    export npe_node=$(( npe_node_max / nth ))
    export NTASKS=${npe}
    export memory="10GB"
    ;;

  # The wavepost*pnt* jobs are I/O heavy and do not scale well to large nodes.
  # Limit the number of tasks/node to 40.
  "wavepostbndpnt")
    export wtime="03:00:00"
    export npe=240
    export nth=1
    export npe_node=$(( npe_node_max / nth ))
    export is_exclusive=True
    if [[ ${npe_node} -gt 40 ]]; then
        export npe_node=40
        export is_exclusive=False
    fi
    export NTASKS=${npe}
    ;;

  "wavepostbndpntbll")
    export wtime="01:00:00"
    export npe=448
    export nth=1
    export npe_node=$(( npe_node_max / nth ))
    export is_exclusive=True
    if [[ ${npe_node} -gt 40 ]]; then
        export npe_node=40
        export is_exclusive=False
    fi
    export NTASKS=${npe}
    ;;

  "wavepostpnt")
    export wtime="04:00:00"
    export npe=200
    export nth=1
    export npe_node=$(( npe_node_max / nth ))
    export is_exclusive=True
    if [[ ${npe_node} -gt 40 ]]; then
        export npe_node=40
        export is_exclusive=False
    fi
    export NTASKS=${npe}
    ;;

  *)
    echo "FATAL ERROR: Invalid job ${step} passed to ${BASH_SOURCE[0]}"
    exit 1
    ;;

esac

echo "END: config.resources"
